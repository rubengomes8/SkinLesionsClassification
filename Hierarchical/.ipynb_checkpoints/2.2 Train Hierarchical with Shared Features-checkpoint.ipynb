{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "import csv\n",
    "from numpy import array\n",
    "from operator import itemgetter\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(path):\n",
    "    target = []\n",
    "    target_a = []\n",
    "    target_b = []\n",
    "    target_c = []\n",
    "    target_d = []\n",
    "    target_e = []\n",
    "\n",
    "    counter = {'MEL': 0, 'NV': 0, 'BCC': 0, 'AKIEC': 0, 'BKL': 0, 'DF': 0, 'VASC': 0}\n",
    "    i = 0\n",
    "    with open(path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            if row[1] == '1.0':  # MEL\n",
    "                counter['MEL'] += 1\n",
    "                target.append(0)\n",
    "                target_a.append(0)\n",
    "                target_b.append(0)\n",
    "                target_c.append(-1)\n",
    "                target_d.append(-1)\n",
    "                target_e.append(-1)\n",
    "\n",
    "            elif row[2] == '1.0':  # NV\n",
    "                counter['NV'] += 1\n",
    "                target.append(1)\n",
    "                target_a.append(0)\n",
    "                target_b.append(1)\n",
    "                target_c.append(-1)\n",
    "                target_d.append(-1)\n",
    "                target_e.append(-1)\n",
    "\n",
    "            elif row[3] == '1.0':  # BCC\n",
    "                counter['BCC'] += 1\n",
    "                target.append(2)\n",
    "                target_a.append(1)\n",
    "                target_b.append(-1)\n",
    "                target_c.append(0)\n",
    "                target_d.append(-1)\n",
    "                target_e.append(0)\n",
    "\n",
    "            elif row[4] == '1.0':  # AKIEC\n",
    "                counter['AKIEC'] += 1\n",
    "                target.append(3)\n",
    "                target_a.append(1)\n",
    "                target_b.append(-1)\n",
    "                target_c.append(0)\n",
    "                target_d.append(-1)\n",
    "                target_e.append(1)\n",
    "\n",
    "            elif row[5] == '1.0':  # BKL\n",
    "                counter['BKL'] += 1\n",
    "                target.append(4)\n",
    "                target_a.append(1)\n",
    "                target_b.append(-1)\n",
    "                target_c.append(1)\n",
    "                target_d.append(0)\n",
    "                target_e.append(-1)\n",
    "\n",
    "            elif row[6] == '1.0':  # DF\n",
    "                counter['DF'] += 1\n",
    "                target.append(5)\n",
    "                target_a.append(1)\n",
    "                target_b.append(-1)\n",
    "                target_c.append(1)\n",
    "                target_d.append(1)\n",
    "                target_e.append(-1)\n",
    "\n",
    "            elif row[7] == '1.0':  # VASC\n",
    "                counter['VASC'] += 1\n",
    "                target.append(6)  # BCC\n",
    "                target_a.append(1)\n",
    "                target_b.append(-1)\n",
    "                target_c.append(1)\n",
    "                target_d.append(2)\n",
    "                target_e.append(-1)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    print(counter)\n",
    "    file.close()\n",
    "    return target, target_a, target_b, target_c, target_d, target_e, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports all the images from a specified folder, with a specific extension\n",
    "# and resizes to a specific imgHeight, imgWidth\n",
    "\n",
    "def import_dataset(path, mode, fileExtension='.jpg', imgWidth=224, imgHeight=224):\n",
    "    datasetFilenamesImages = []\n",
    "    dataset = []\n",
    "    print(\"Start importing \" + mode + \" images...\")\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(fileExtension): \n",
    "            completePath = os.path.join(path, filename)\n",
    "            image = cv2.imread(completePath, cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, dsize=(imgHeight, imgWidth), interpolation=cv2.INTER_AREA)\n",
    "            filenameImage = [filename, image]\n",
    "            datasetFilenamesImages.append(filenameImage)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    datasetFilenamesImages = sorted(datasetFilenamesImages, key=itemgetter(0))\n",
    "    for x in datasetFilenamesImages:\n",
    "        dataset.append(x[1])\n",
    "    \n",
    "    return array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(imgHeight = 224, imgWidth = 224):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(imgHeight, imgWidth, 3)) # inputs.shape, inputs.dtype\n",
    "    densenet = DenseNet121(include_top=False, weights='imagenet')\n",
    "    x = densenet(inputs)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    a = Dense(2, activation='softmax', name=\"model_a\")(x)\n",
    "    b = Dense(2, activation='softmax', name=\"model_b\")(x)\n",
    "    c = Dense(2, activation='softmax', name=\"model_c\")(x)\n",
    "    d = Dense(3, activation='softmax', name=\"model_d\")(x)\n",
    "    e = Dense(2, activation='softmax', name=\"model_e\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[a, b, c, d, e], name='global_loss')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical_custom(array, num_classes=2):\n",
    "    categorical = []\n",
    "    for i in range(len(array)):\n",
    "        if array[i] == -1:\n",
    "            categorical.append(np.zeros(num_classes, dtype=np.float))\n",
    "        elif array[i] == 0:\n",
    "            a = np.zeros(num_classes, dtype=np.float)\n",
    "            a[0] = float(1)\n",
    "            categorical.append(a)\n",
    "        elif array[i] == 1:\n",
    "            a = np.zeros(num_classes, dtype=np.float)\n",
    "            a[1] = float(1)\n",
    "            categorical.append(a)\n",
    "        elif array[i] == 2:\n",
    "            a = np.zeros(num_classes, dtype=np.float)\n",
    "            a[2] = float(1)\n",
    "            categorical.append(a)\n",
    "    return categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(array):\n",
    "    d = {-1: 0, 0: 0, 1: 0, 2: 0}\n",
    "    for i in range(len(array)):\n",
    "        d[array[i]] += 1\n",
    "\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs = 25\n",
    "lr = 1e-5\n",
    "\n",
    "p_train = '/home/ruben/Desktop/smalltrain2018'\n",
    "t_train = '/home/ruben/Desktop/smalltrain2018/labels.csv'\n",
    "\n",
    "p_val = '/home/ruben/Desktop/smallval2018'\n",
    "t_val = '/home/ruben/Desktop/smallval2018/labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    " print(tf.executing_eagerly())\n",
    "    x_train = import_dataset(p_train, 'training')\n",
    "    x_val = import_dataset(p_val, 'val')\n",
    "\n",
    "    y_train, y_a, y_b, y_c, y_d, y_e, counter_train = create_labels(t_train)\n",
    "    y_val, y_val_a, y_val_b, y_val_c, y_val_d, y_val_e, counter_val = create_labels(t_val)\n",
    "\n",
    "    count_labels(y_a)\n",
    "    count_labels(y_b)\n",
    "    count_labels(y_c)\n",
    "    count_labels(y_d)\n",
    "    count_labels(y_e)\n",
    "\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    losses = {\n",
    "        \"model_a\": \"categorical_crossentropy\",\n",
    "        \"model_b\": \"categorical_crossentropy\",\n",
    "        \"model_c\": \"categorical_crossentropy\",\n",
    "        \"model_d\": \"categorical_crossentropy\",\n",
    "        \"model_e\": \"categorical_crossentropy\"\n",
    "    }\n",
    "\n",
    "    adam = Adam(lr=1e-5)\n",
    "    model.compile(optimizer=adam, loss=losses,\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    y_a_cat = to_categorical_custom(y_a, num_classes=2) # fazer customizado,\n",
    "    y_b_cat = to_categorical_custom(y_b, num_classes=2)\n",
    "    y_c_cat = to_categorical_custom(y_c, num_classes=2)\n",
    "    y_d_cat = to_categorical_custom(y_d, num_classes=3)\n",
    "    y_e_cat = to_categorical_custom(y_e, num_classes=2)\n",
    "    y_val_a_cat = to_categorical_custom(y_val_a, num_classes=2)\n",
    "    y_val_b_cat = to_categorical_custom(y_val_b, num_classes=2)\n",
    "    y_val_c_cat = to_categorical_custom(y_val_c, num_classes=2)\n",
    "    y_val_d_cat = to_categorical_custom(y_val_d, num_classes=3)\n",
    "    y_val_e_cat = to_categorical_custom(y_val_e, num_classes=2)\n",
    "\n",
    "\n",
    "    y_val_cat = to_categorical(y_val)\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "    print(tf.executing_eagerly())\n",
    "\n",
    "    checkpoint_path = \"/home/ruben/Desktop/Boss/small_dataset_v2_weights/cp.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1, save_best_only=True)\n",
    "\n",
    "    def scheduler(epoch):\n",
    "        global no_epochs\n",
    "        global lr\n",
    "        if epoch < int(0.5 * no_epochs):\n",
    "            return lr\n",
    "        elif epoch < int(0.75 * no_epochs):\n",
    "            print(\"Redução do lr /10\")\n",
    "            return lr / 10.\n",
    "        else:\n",
    "            print(\"Redução do lr /100\")\n",
    "            return lr / 100.\n",
    "\n",
    "    scheduler_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    class_weights_a = {0: 10608. / 8361, 1: 10608. / 2247}\n",
    "    class_weights_b = {0: 8361. / 1212, 1: 8361. / 7149}\n",
    "    class_weights_c = {0: 2247. / 879, 1: 2247. / 1368}\n",
    "    class_weights_d = {0: 1368. / 1101, 1: 1368. / 114, 2: 1368. / 153}\n",
    "    class_weights_e = {0: 879. / 519, 1: 879. / 360}\n",
    "    class_weights = [class_weights_a, class_weights_b, class_weights_c, class_weights_d, class_weights_e]\n",
    "\n",
    "    fit = model.fit(x_train, [y_a_cat, y_b_cat, y_c_cat, y_d_cat, y_e_cat], batch_size=10, epochs=no_epochs, callbacks=[cp_callback, scheduler_cb],\n",
    "                    class_weight=class_weights, validation_data=(x_val, [y_val_a_cat, y_val_b_cat, y_val_c_cat, y_val_d_cat, y_val_e_cat])) # class_weights?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
