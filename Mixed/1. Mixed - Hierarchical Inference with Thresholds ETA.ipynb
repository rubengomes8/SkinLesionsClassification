{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from operator import itemgetter\n",
    "from numpy import array\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports all the images from a specified folder, with a specific extension\n",
    "# and resizes to a specific imgHeight, imgWidth\n",
    "\n",
    "def import_dataset(path, mode, fileExtension='.jpg', imgWidth=224, imgHeight=224):\n",
    "    datasetFilenamesImages = []\n",
    "    dataset = []\n",
    "    print(\"Start importing \" + mode + \" images...\")\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(fileExtension): \n",
    "            completePath = os.path.join(path, filename)\n",
    "            image = cv2.imread(completePath, cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, dsize=(imgHeight, imgWidth), interpolation=cv2.INTER_AREA)\n",
    "            filenameImage = [filename, image]\n",
    "            datasetFilenamesImages.append(filenameImage)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    datasetFilenamesImages = sorted(datasetFilenamesImages, key=itemgetter(0))\n",
    "    for x in datasetFilenamesImages:\n",
    "        dataset.append(x[1])\n",
    "    \n",
    "    return array(dataset)\n",
    "\n",
    "\n",
    "def assign_labels(path_groundtruth):\n",
    "    target = []\n",
    "    counter = {'MEL': 0, 'NV': 0, 'BCC': 0, 'AKIEC': 0, 'BKL': 0, 'DF': 0, 'VASC': 0}\n",
    "    i=0\n",
    "    with open(path_groundtruth, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            if row[1] == '1.0': # MEL\n",
    "                counter['MEL'] += 1\n",
    "                target.append(0)\n",
    "            elif row[2] == '1.0': # NV\n",
    "                counter['NV'] += 1\n",
    "                target.append(1)\n",
    "            elif row[3] == '1.0': # BCC\n",
    "                counter['BCC'] += 1\n",
    "                target.append(2)\n",
    "            elif row[4] == '1.0': # AKIEC\n",
    "                counter['AKIEC'] += 1\n",
    "                target.append(3)\n",
    "            elif row[5] == '1.0': # BKL\n",
    "                counter['BKL'] += 1\n",
    "                target.append(4)\n",
    "            elif row[6] == '1.0': # DF\n",
    "                counter['DF'] += 1\n",
    "                target.append(5)\n",
    "            elif row[7] == '1.0':   # VASC\n",
    "                counter['VASC'] += 1\n",
    "                target.append(6) # BCC\n",
    "            else:\n",
    "                continue\n",
    "    print(counter)\n",
    "    file.close()\n",
    "    return counter, target\n",
    "\n",
    "\n",
    "def create_model(model = 'densenet', noClasses=2, imgWidth=224, imgHeight=224):\n",
    "    if model == 'densenet':\n",
    "        densenet = DenseNet121(include_top=False, weights=None, input_shape=(imgHeight, imgWidth, 3))\n",
    "        model = tf.keras.Sequential(densenet)\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(Dense(units=noClasses, activation=\"softmax\"))\n",
    "    elif model == 'resnet':\n",
    "        from tensorflow.keras.applications.resnet import ResNet101\n",
    "        resnet = ResNet101(include_top=False, weights=None, input_shape=(imgHeight, imgWidth, 3))\n",
    "        model = tf.keras.Sequential(densenet)\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(Dense(units=noClasses, activation=\"softmax\"))\n",
    "    else:\n",
    "        print(\"That model is not available.\")\n",
    "        exit(0)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f24104453a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 5 classifiers and load the weights\n",
    "\n",
    "model1 = create_model('densenet', 2) # MEL vs NMEL\n",
    "model2 = create_model('densenet', 2) # NV vs MELA\n",
    "model3 = create_model('densenet', 2) # BEN vs MAL\n",
    "model4 = create_model('densenet', 3) # BKL vs DF vs VASC\n",
    "model5 = create_model('densenet', 2) # AKIEC vs BCC\n",
    "\n",
    "ckpt1_path = \"/home/ruben/Desktop/isic_2018/model_weights/hier/densenet/a/cp.ckpt\"\n",
    "ckpt2_path = \"/home/ruben/Desktop/isic_2018/model_weights/hier/densenet/b/cp.ckpt\"\n",
    "ckpt3_path = \"/home/ruben/Desktop/isic_2018/model_weights/hier/densenet/c/cp.ckpt\"\n",
    "ckpt4_path = \"/home/ruben/Desktop/isic_2018/model_weights/hier/densenet/d/cp.ckpt\"\n",
    "ckpt5_path = \"/home/ruben/Desktop/isic_2018/model_weights/hier/densenet/e/cp.ckpt\"\n",
    "\n",
    "model1.load_weights(ckpt1_path)\n",
    "model2.load_weights(ckpt2_path)\n",
    "model3.load_weights(ckpt3_path)\n",
    "model4.load_weights(ckpt4_path)\n",
    "model5.load_weights(ckpt5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f24a51353a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create flat model\n",
    "\n",
    "flat_path = '/home/ruben/Desktop/isic_2018/model_weights/flat/densenet/cp.ckpt'\n",
    "x_flat = []\n",
    "y_flat = []\n",
    "\n",
    "flat = create_model('densenet', 7)\n",
    "flat.load_weights(flat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ETA thresholds\n",
    "\n",
    "eta_a = 0.6\n",
    "eta_b = 0.6\n",
    "eta_c = 0.6\n",
    "eta_d = 0.6\n",
    "eta_e = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MEL': 1, 'NV': 1, 'BCC': 1, 'AKIEC': 1, 'BKL': 1, 'DF': 1, 'VASC': 1}\n",
      "Start importing validation images...\n",
      "len(x_a):  7\n",
      "len(y_a):  7\n"
     ]
    }
   ],
   "source": [
    "p_val = '/home/ruben/Desktop/isic_2018/val_2018'\n",
    "t_val = '/home/ruben/Desktop/isic_2018/val_2018/labels.csv'\n",
    "\n",
    "counter, y_a = assign_labels(t_val)\n",
    "x_a = import_dataset(p_val, 'validation')\n",
    "print(\"len(x_a): \", len(x_a))\n",
    "print(\"len(y_a): \", len(y_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-2397e2979482>:9: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "x_b = []\n",
    "x_c = []\n",
    "y_b = []\n",
    "y_c = []\n",
    "indexes_a_nmel = []\n",
    "indexes_a_mel = []\n",
    "\n",
    "if len(x_a) >= 1:\n",
    "    y_hat_a = model1.predict_classes(x_a)\n",
    "    y_hat_a_probabilities = model1.predict(x_a)\n",
    "    \n",
    "    x_a_aux = []\n",
    "    y_a_aux = []\n",
    "    y_hat_a_aux = []\n",
    "    \n",
    "    for i in range(0, len(y_hat_a_probabilities)):\n",
    "        probabilitiesList = y_hat_a_probabilities[i]\n",
    "        probabilitiesList.sort()\n",
    "        highestProb = probabilitiesList[1]\n",
    "        secondHighestProb = probabilitiesList[0]\n",
    "        if (highestProb - secondHighestProb) < eta_a:\n",
    "            x_flat.append(x_a[i])\n",
    "            y_flat.append(y_a[i])\n",
    "        else:\n",
    "            x_a_aux.append(x_a[i])\n",
    "            y_a_aux.append(y_a[i])\n",
    "            y_hat_a_aux.append(y_hat_a[i])\n",
    "    \n",
    "    x_a = array(x_a_aux)\n",
    "    y_a = y_a_aux\n",
    "    y_hat_a = y_hat_a_aux\n",
    "     \n",
    "if len(x_a) >= 1:\n",
    "    for i in range(0, len(y_hat_a)):\n",
    "        if y_hat_a[i] == 1: # NMEL\n",
    "            # indexes: what indexes of y_hat_a are nmel lesions\n",
    "            indexes_a_nmel.append(i)\n",
    "            x_c.append(x_a[i])\n",
    "            y_c.append(y_a[i])\n",
    "\n",
    "        elif y_hat_a[i] == 0: # MEL\n",
    "            indexes_a_mel.append(i)\n",
    "            x_b.append(x_a[i])\n",
    "            y_b.append(y_a[i])\n",
    "\n",
    "    x_b = array(x_b)\n",
    "    x_c = array(x_c)\n",
    "\n",
    "    print(\"len(y_hat_a): \", len(y_hat_a))\n",
    "    print(\"len(x_b): \", len(x_b))\n",
    "    print(\"len(x_c): \", len(x_c))  \n",
    "else:\n",
    "    x_b = []\n",
    "    x_c = []\n",
    "    x_b = array(x_b)\n",
    "    x_c = array(x_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b_aux = []\n",
    "y_b_aux = []\n",
    "y_hat_b_aux = []\n",
    "    \n",
    "if(len(x_b) != 0):\n",
    "    y_hat_b = model2.predict_classes(x_b)\n",
    "    y_hat_b_probabilities = model2.predict(x_b)\n",
    "    \n",
    "    for i in range(0, len(y_hat_b_probabilities)):\n",
    "        probabilitiesList = y_hat_b_probabilities[i]\n",
    "        probabilitiesList.sort()\n",
    "        highestProb = probabilitiesList[1]\n",
    "        secondHighestProb = probabilitiesList[0]\n",
    "        if (highestProb - secondHighestProb) < eta_b:\n",
    "            x_flat.append(x_b[i])\n",
    "            y_flat.append(y_b[i])\n",
    "        else:\n",
    "            x_b_aux.append(x_b[i])\n",
    "            y_b_aux.append(y_b[i])\n",
    "            y_hat_b_aux.append(y_hat_b[i])\n",
    "        \n",
    "else:\n",
    "    y_hat_b = []\n",
    "    \n",
    "x_b = array(x_b_aux)\n",
    "y_b = y_b_aux\n",
    "y_hat_b = y_hat_b_aux\n",
    "zippedList = list(zip(y_hat_b, y_b))\n",
    "df_b = pd.DataFrame(zippedList, columns = ['MEL_PRED', 'MEL_TRUTH'])\n",
    "df_b.to_csv('/home/ruben/Desktop/classifier_b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_c_mal = []\n",
    "indexes_c_ben = []\n",
    "\n",
    "if(len(x_c) != 0):\n",
    "    y_hat_c = model3.predict_classes(x_c)\n",
    "    y_hat_c_probabilities = model3.predict(x_c)\n",
    "    \n",
    "    x_c_aux = []\n",
    "    y_c_aux = []\n",
    "    y_hat_c_aux = []\n",
    "\n",
    "    for i in range(0, len(y_hat_c_probabilities)):\n",
    "        \n",
    "        probabilitiesList = y_hat_c_probabilities[i]\n",
    "        probabilitiesList.sort()\n",
    "        highestProb = probabilitiesList[1]\n",
    "        secondHighestProb = probabilitiesList[0]\n",
    "        \n",
    "        if (highestProb - secondHighestProb) < eta_c:\n",
    "            x_flat.append(x_c[i])\n",
    "            y_flat.append(y_c[i])\n",
    "        else:\n",
    "            x_c_aux.append(x_c[i])\n",
    "            y_c_aux.append(y_c[i])\n",
    "            y_hat_c_aux.append(y_hat_c[i])\n",
    "    \n",
    "    x_c = array(x_c_aux)\n",
    "    y_c = y_c_aux\n",
    "    y_hat_c = y_hat_c_aux\n",
    "\n",
    "    print(\"len(y_hat_c): \", len(y_hat_c))\n",
    "    print(\"len(x_d): \", len(x_d))\n",
    "    print(\"len(x_e): \", len(x_e))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d = []\n",
    "x_e = []\n",
    "y_d = []\n",
    "y_e = []\n",
    "\n",
    "if len(x_c) >= 1:\n",
    "    \n",
    "    for i in range(0, len(y_hat_c)):\n",
    "\n",
    "        if y_hat_c[i] == 1: # MAL\n",
    "            indexes_c_mal.append(i)\n",
    "            x_e.append(x_c[i])\n",
    "            y_e.append(y_c[i])\n",
    "\n",
    "\n",
    "        elif y_nmel_pred[i] == 0: # BEN\n",
    "            indexes_2_ben.append(i)\n",
    "            x_d.append(x_c[i])\n",
    "            y_d.append(y_c[i])\n",
    "\n",
    "\n",
    "    x_d = array(x_d)\n",
    "    x_e = array(x_e)\n",
    "    \n",
    "else:\n",
    "    x_d = []\n",
    "    x_e = []\n",
    "    x_d = array(x_d)\n",
    "    x_e = array(x_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(x_d) != 0):\n",
    "    y_hat_d = model4.predict_classes(x_d)\n",
    "    y_hat_d_probabilities = model4.predict(x_d)\n",
    "    \n",
    "    x_d_aux = []\n",
    "    y_d_aux = []\n",
    "    y_hat_d_aux = []\n",
    "\n",
    "    for i in range(0, len(y_hat_d_probabilities)):\n",
    "        \n",
    "        probabilitiesList = y_hat_d_probabilities[i]\n",
    "        probabilitiesList.sort()\n",
    "        highestProb = probabilitiesList[1]\n",
    "        secondHighestProb = probabilitiesList[0]\n",
    "        \n",
    "        if (highestProb - secondHighestProb) < eta_d:\n",
    "            x_flat.append(x_d[i])\n",
    "            y_flat.append(y_d[i])\n",
    "        else:\n",
    "            x_d_aux.append(x_d[i])\n",
    "            y_d_aux.append(y_d[i])\n",
    "            y_hat_d_aux.append(y_hat_d[i])\n",
    "else:\n",
    "    y_hat_d = []\n",
    "\n",
    "zippedList = list(zip(y_hat_d, y_d))\n",
    "df_d = pd.DataFrame(zippedList, columns = ['BEN_PRED', 'BEN_TRUTH'])\n",
    "df_d.to_csv('/home/ruben/Desktop/classifier_d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e_aux = []\n",
    "y_e_aux = []\n",
    "y_hat_e_aux = []\n",
    "    \n",
    "if(len(x_e) != 0):\n",
    "    y_hat_e = model5.predict_classes(x_e)\n",
    "    y_hat_e_probabilities = model5.predict(x_e)\n",
    "\n",
    "    for i in range(0, len(y_hat_e_probabilities)):\n",
    "        \n",
    "        probabilitiesList = y_hat_e_probabilities[i]\n",
    "        probabilitiesList.sort()\n",
    "        highestProb = probabilitiesList[1]\n",
    "        secondHighestProb = probabilitiesList[0]\n",
    "        \n",
    "        if (highestProb - secondHighestProb) < eta_e:\n",
    "            x_flat.append(x_e[i])\n",
    "            y_flat.append(y_e[i])\n",
    "        else:\n",
    "            x_e_aux.append(x_e[i])\n",
    "            y_e_aux.append(y_e[i])\n",
    "            y_hat_e_aux.append(y_hat_e[i])\n",
    "    \n",
    "else:\n",
    "    y_hat_e = []\n",
    "    \n",
    "zippedList = list(zip(y_hat_e, y_e))\n",
    "df_e = pd.DataFrame(zippedList, columns = ['MAL_PRED', 'MAL_TRUTH'])\n",
    "df_e.to_csv('/home/ruben/Desktop/classifier_e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(x_flat) >= 1:\n",
    "    x_flat = array(x_flat)\n",
    "    y_hat_flat = flat.predict_classes(x_flat)\n",
    "    \n",
    "else:\n",
    "    y_hat_flat = []\n",
    "   \n",
    "\n",
    "zippedList = list(zip(y_hat_flat, y_flat))\n",
    "df_flat = pd.DataFrame(zippedList, columns = ['FLAT_PRED', 'FLAT_TRUTH'])\n",
    "df_flat.to_csv('/home/ruben/Desktop/flat_classifier.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
